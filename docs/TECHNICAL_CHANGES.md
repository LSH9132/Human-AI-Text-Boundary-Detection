# ê¸°ìˆ ì  ë³€ê²½ ì‚¬í•­ ìƒì„¸ ë¬¸ì„œ

## ğŸ“‹ íŒŒì¼ë³„ ë³€ê²½ ì‚¬í•­

### 1. `src/model_trainer.py` - í´ë˜ìŠ¤ ë¶ˆê· í˜• í•´ê²°

#### ğŸ†• ì¶”ê°€ëœ í´ë˜ìŠ¤: FocalLoss
```python
class FocalLoss(nn.Module):
    """Focal Loss for addressing class imbalance."""
    
    def __init__(self, alpha=1.0, gamma=2.0, reduction='mean'):
        super(FocalLoss, self).__init__()
        self.alpha = alpha
        self.gamma = gamma
        self.reduction = reduction
    
    def forward(self, inputs, targets):
        bce_loss = F.binary_cross_entropy_with_logits(inputs, targets, reduction='none')
        p_t = torch.exp(-bce_loss)
        focal_weight = (1 - p_t) ** self.gamma
        
        if self.alpha is not None:
            alpha_t = self.alpha * targets + (1 - self.alpha) * (1 - targets)
            focal_loss = alpha_t * focal_weight * bce_loss
        else:
            focal_loss = focal_weight * bce_loss
        
        return focal_loss.mean() if self.reduction == 'mean' else focal_loss
```

#### ğŸ”„ ë³€ê²½ëœ ë©”ì„œë“œ: train_single_fold
```python
# ì´ì „ ì½”ë“œ
pos_weight = torch.tensor(11.2, device=self.device)
criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)

# ë³€ê²½ëœ ì½”ë“œ
pos_count = sum(train_dataset.labels)
neg_count = len(train_dataset.labels) - pos_count
pos_weight = torch.tensor(neg_count / pos_count, device=self.device)

loss_type = getattr(self.config.training, 'loss_function', 'bce_weighted')

if loss_type == 'focal':
    alpha = pos_count / (pos_count + neg_count)
    criterion = FocalLoss(alpha=alpha, gamma=2.0)
else:
    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)
```

#### ğŸ†• ì¶”ê°€ëœ ë©”ì„œë“œ: _create_document_aware_splits
```python
def _create_document_aware_splits(self, train_data: List[str], train_labels: List[int], 
                                 document_ids: List[str]) -> List[Tuple[List[int], List[int]]]:
    """
    Create document-aware cross-validation splits.
    Ensures paragraphs from the same document don't appear in both train and validation sets.
    """
    import pandas as pd
    
    df = pd.DataFrame({
        'text': train_data,
        'label': train_labels,
        'document_id': document_ids
    })
    
    doc_groups = df.groupby('document_id')
    doc_info = []
    
    for doc_id, group in doc_groups:
        doc_label = group['label'].iloc[0]
        doc_indices = group.index.tolist()
        doc_info.append({
            'document_id': doc_id,
            'label': doc_label,
            'indices': doc_indices,
            'size': len(doc_indices)
        })
    
    doc_info.sort(key=lambda x: x['size'], reverse=True)
    
    splits = []
    n_splits = self.config.training.n_splits
    
    for fold in range(n_splits):
        fold_docs = [doc for i, doc in enumerate(doc_info) if i % n_splits == fold]
        
        val_indices = []
        for doc in fold_docs:
            val_indices.extend(doc['indices'])
        
        train_indices = []
        for i, doc in enumerate(doc_info):
            if i % n_splits != fold:
                train_indices.extend(doc['indices'])
        
        splits.append((train_indices, val_indices))
    
    return splits
```

#### ğŸ”„ ë³€ê²½ëœ ë©”ì„œë“œ: cross_validate
```python
# ì´ì „ ì½”ë“œ
skf = StratifiedKFold(n_splits=self.config.training.n_splits, shuffle=True, random_state=42)
for fold, (train_idx, val_idx) in enumerate(skf.split(train_data, train_labels)):

# ë³€ê²½ëœ ì½”ë“œ
if document_ids is not None:
    self.logger.info("Using document-aware cross-validation")
    splits = self._create_document_aware_splits(train_data, train_labels, document_ids)
else:
    self.logger.info("Using standard stratified cross-validation")
    skf = StratifiedKFold(n_splits=self.config.training.n_splits, shuffle=True, random_state=42)
    splits = list(skf.split(train_data, train_labels))

for fold, (train_idx, val_idx) in enumerate(splits):
```

---

### 2. `src/config.py` - ëª¨ë¸ ë° ì„¤ì • ìµœì í™”

#### ğŸ”„ ë³€ê²½ëœ í´ë˜ìŠ¤: ModelConfig
```python
@dataclass
class ModelConfig:
    """Model configuration parameters."""
    model_name: str = 'klue/bert-base'
    max_length: int = 256
    num_labels: int = 1
    dropout_rate: float = 0.1
    
    # ğŸ†• ì¶”ê°€ëœ ë¶€ë¶„
    alternative_models: Dict[str, str] = None
    
    def __post_init__(self):
        if self.alternative_models is None:
            self.alternative_models = {
                'klue-bert': 'klue/bert-base',
                'koelectra': 'monologg/koelectra-base-v3-discriminator',
                'kcbert': 'beomi/kcbert-base',
                'kobert': 'skt/kobert-base-v1',
                'kobigbird': 'monologg/kobigbird-bert-base'
            }
```

#### ğŸ”„ ë³€ê²½ëœ í´ë˜ìŠ¤: TrainingConfig
```python
@dataclass
class TrainingConfig:
    # ê¸°ì¡´ ì„¤ì •ë“¤...
    
    # ğŸ†• ì¶”ê°€ëœ ì„¤ì •
    loss_function: str = 'focal'  # 'bce_weighted', 'focal', 'bce'
```

#### ğŸ”„ ë³€ê²½ëœ í´ë˜ìŠ¤: DataConfig
```python
@dataclass
class DataConfig:
    # ê¸°ì¡´ ì„¤ì •ë“¤...
    
    # ğŸ”„ ë³€ê²½ëœ ì„¤ì •
    max_paragraphs_per_document: int = 10  # ì´ì „: 3 â†’ ì´í›„: 10
```

#### ğŸ†• ì¶”ê°€ëœ í•¨ìˆ˜: get_config_for_model
```python
def get_config_for_model(model_name: str = 'klue-bert') -> Config:
    """Get configuration optimized for specific model."""
    config = Config()
    
    if model_name == 'koelectra':
        config.model.model_name = 'monologg/koelectra-base-v3-discriminator'
        config.model.max_length = 512
        config.training.batch_size = 16
        config.training.learning_rate = 3e-5
        config.training.loss_function = 'focal'
        config.data.max_paragraphs_per_document = 15
    elif model_name == 'kcbert':
        config.model.model_name = 'beomi/kcbert-base'
        config.model.max_length = 300
        config.training.batch_size = 24
        config.training.learning_rate = 2e-5
        config.training.loss_function = 'focal'
        config.data.max_paragraphs_per_document = 12
    # ... ê¸°íƒ€ ëª¨ë¸ ì„¤ì •
    
    return config
```

---

### 3. `src/predictor.py` - ì•™ìƒë¸” ìµœì í™”

#### ğŸ†• ì¶”ê°€ëœ ë©”ì„œë“œ: predict_with_ensemble
```python
def predict_with_ensemble(self, test_texts: List[str], model_paths: List[str],
                         ensemble_method: str = 'weighted_mean') -> List[float]:
    """Advanced ensemble prediction with multiple methods."""
    
    all_predictions = []
    model_weights = []
    
    for i, model_path in enumerate(model_paths):
        model = self.load_model(model_path)
        preds = self.predict_batch(model, test_texts)
        all_predictions.append(preds)
        
        # Calculate model weight based on file size
        weight = os.path.getsize(model_path) / 1e6 if os.path.exists(model_path) else 1.0
        model_weights.append(weight)
        
        if self.device.type == 'cuda':
            torch.cuda.empty_cache()
    
    # Normalize weights
    model_weights = np.array(model_weights) / np.sum(model_weights)
    all_predictions = np.array(all_predictions)
    
    if ensemble_method == 'mean':
        ensemble_preds = np.mean(all_predictions, axis=0)
    elif ensemble_method == 'weighted_mean':
        ensemble_preds = np.average(all_predictions, axis=0, weights=model_weights)
    elif ensemble_method == 'median':
        ensemble_preds = np.median(all_predictions, axis=0)
    # ... ê¸°íƒ€ ì•™ìƒë¸” ë°©ë²•
    
    return ensemble_preds.tolist()
```

#### ğŸ†• ì¶”ê°€ëœ ë©”ì„œë“œ: optimize_ensemble_weights
```python
def optimize_ensemble_weights(self, validation_texts: List[str], validation_labels: List[int],
                             model_paths: List[str]) -> List[float]:
    """Optimize ensemble weights based on validation performance."""
    from sklearn.metrics import roc_auc_score
    from scipy.optimize import minimize
    
    # Get predictions from all models
    all_val_preds = []
    for model_path in model_paths:
        model = self.load_model(model_path)
        preds = self.predict_batch(model, validation_texts)
        all_val_preds.append(preds)
    
    all_val_preds = np.array(all_val_preds)
    
    # Objective function to minimize (negative AUC)
    def objective(weights):
        weights = weights / np.sum(weights)
        ensemble_preds = np.average(all_val_preds, axis=0, weights=weights)
        try:
            auc = roc_auc_score(validation_labels, ensemble_preds)
            return -auc
        except:
            return 1.0
    
    # Optimize weights
    initial_weights = np.ones(len(model_paths)) / len(model_paths)
    constraints = {'type': 'eq', 'fun': lambda w: np.sum(w) - 1}
    bounds = [(0, 1) for _ in range(len(model_paths))]
    
    result = minimize(objective, initial_weights, method='SLSQP', 
                     bounds=bounds, constraints=constraints)
    
    return result.x.tolist() if result.success else initial_weights.tolist()
```

#### ğŸ†• ì¶”ê°€ëœ ë©”ì„œë“œ: apply_context_adjustment
```python
def apply_context_adjustment(self, test_df: pd.DataFrame, predictions: List[float]) -> List[float]:
    """Apply document-level context adjustment to predictions."""
    
    adjusted_predictions = []
    test_df_copy = test_df.copy()
    test_df_copy['predictions'] = predictions
    
    for title, group in test_df_copy.groupby('title'):
        doc_preds = group['predictions'].tolist()
        doc_avg = np.mean(doc_preds)
        
        adjusted_preds = []
        for pred in doc_preds:
            adjusted = (
                (1 - self.config.training.context_weight) * pred + 
                self.config.training.context_weight * doc_avg
            )
            adjusted_preds.append(adjusted)
        
        adjusted_predictions.extend(adjusted_preds)
    
    return adjusted_predictions
```

---

### 4. ìƒˆë¡œìš´ íŒŒì¼ë“¤

#### ğŸ†• `data_augmentation/korean_augment.py`
```python
class KoreanTextAugmenter:
    """Korean text augmentation class."""
    
    def __init__(self, aug_prob: float = 0.3):
        self.aug_prob = aug_prob
        self.synonyms = {
            'ê·¸ë¦¬ê³ ': ['ë˜í•œ', 'ê·¸ë˜ì„œ', 'ë”ë¶ˆì–´', 'ì•„ìš¸ëŸ¬'],
            'í•˜ì§€ë§Œ': ['ê·¸ëŸ¬ë‚˜', 'ê·¸ëŸ°ë°', 'ë‹¤ë§Œ', 'ë‹¨ì§€'],
            'ì¤‘ìš”í•œ': ['ì£¼ìš”í•œ', 'í•µì‹¬ì ì¸', 'í•„ìˆ˜ì ì¸', 'ì¤‘ëŒ€í•œ'],
            # ... ë” ë§ì€ ë™ì˜ì–´
        }
    
    def augment_text(self, text: str, num_augmented: int = 1) -> List[str]:
        """Generate augmented versions of the input text."""
        augmented_texts = []
        
        for _ in range(num_augmented):
            augmented = text
            
            if random.random() < self.aug_prob:
                augmented = self.synonym_replacement(augmented)
            if random.random() < self.aug_prob:
                augmented = self.sentence_reordering(augmented)
            if random.random() < self.aug_prob:
                augmented = self.connector_variation(augmented)
            
            if augmented != text:
                augmented_texts.append(augmented)
        
        return augmented_texts
    
    def augment_for_balance(self, texts: List[str], labels: List[int], 
                          target_ratio: float = 0.3) -> Tuple[List[str], List[int]]:
        """Augment minority class to achieve better balance."""
        # í´ë˜ìŠ¤ ë¶ˆê· í˜• í•´ê²°ì„ ìœ„í•œ ì˜¤ë²„ìƒ˜í”Œë§ ë¡œì§
        pass
```

#### ğŸ†• `data_augmentation/balanced_sampling.py`
```python
class BalancedSampler:
    """Balanced sampling class for handling class imbalance."""
    
    def oversample_minority(self, texts: List[str], labels: List[int],
                          target_ratio: float = 0.3) -> Tuple[List[str], List[int]]:
        """Oversample minority class to achieve target ratio."""
        # ì†Œìˆ˜ í´ë˜ìŠ¤ ì˜¤ë²„ìƒ˜í”Œë§ ë¡œì§
        pass
    
    def combined_sampling(self, texts: List[str], labels: List[int],
                         target_ratio: float = 0.3, 
                         oversample_ratio: float = 0.7) -> Tuple[List[str], List[int]]:
        """Combine oversampling and undersampling."""
        # ì˜¤ë²„ìƒ˜í”Œë§ + ì–¸ë”ìƒ˜í”Œë§ ì¡°í•© ë¡œì§
        pass
```

#### ğŸ†• `train_improved.py`
```python
def main():
    """Main training function with improved configuration."""
    parser = argparse.ArgumentParser(description='Improved AI Text Detection Training')
    parser.add_argument('--model', type=str, default='klue-bert', 
                       choices=['klue-bert', 'koelectra', 'kcbert', 'kobert'])
    parser.add_argument('--loss', type=str, default='focal',
                       choices=['focal', 'bce_weighted', 'bce'])
    parser.add_argument('--env', type=str, default='gpu',
                       choices=['gpu', 'cpu', 'h100', 'debug'])
    
    args = parser.parse_args()
    
    # Get optimized configuration
    config = get_config_for_model(args.model)
    config.training.loss_function = args.loss
    
    # Initialize improved components
    data_processor = DataProcessor(config.data, config.model)
    model_trainer = ModelTrainer(config)
    predictor = Predictor(config)
    
    # Improved training pipeline
    train_df, test_df = data_processor.load_data()
    train_paragraph_df = data_processor.preprocess_training_data(train_df)
    
    train_texts = train_paragraph_df['paragraph_text'].tolist()
    train_labels = train_paragraph_df['generated'].tolist()
    
    # Train with improved methods
    oof_auc, model_paths = model_trainer.cross_validate(train_texts, train_labels)
    
    # Generate improved predictions
    test_texts = test_df['paragraph_text'].tolist()
    predictions = predictor.predict_with_ensemble(test_texts, model_paths)
    adjusted_predictions = predictor.apply_context_adjustment(test_df, predictions)
    
    # Save results
    submission_df = data_processor.prepare_submission_format(test_df, adjusted_predictions)
    data_processor.save_submission(submission_df, f"improved_submission_{args.model}_{args.loss}.csv")
```

---

## ğŸ“Š ì„±ëŠ¥ í–¥ìƒ ë©”ì»¤ë‹ˆì¦˜

### 1. Focal Loss íš¨ê³¼
```python
# ì¼ë°˜ì ì¸ BCE Loss
loss = -[y*log(p) + (1-y)*log(1-p)]

# Focal Loss
focal_loss = -Î±(1-p)^Î³[y*log(p) + (1-y)*log(1-p)]
```
- **Î±**: í´ë˜ìŠ¤ ë¶ˆê· í˜• ê°€ì¤‘ì¹˜ (ì†Œìˆ˜ í´ë˜ìŠ¤ì— ë” ë§ì€ ê°€ì¤‘ì¹˜)
- **Î³**: ì–´ë ¤ìš´ ìƒ˜í”Œ ê°€ì¤‘ì¹˜ (Î³=2ì¼ ë•Œ ìµœì  ì„±ëŠ¥)

### 2. ë¬¸ì„œë³„ êµì°¨ê²€ì¦ íš¨ê³¼
```python
# ì´ì „: ë¬¸ë‹¨ë³„ ë¶„í•  (ë°ì´í„° ìœ ì¶œ)
Document A: [Para1, Para2, Para3]
Train: [Para1, Para3]  # ê°™ì€ ë¬¸ì„œ
Val:   [Para2]         # ê°™ì€ ë¬¸ì„œ

# ì´í›„: ë¬¸ì„œë³„ ë¶„í•  (ë°ì´í„° ìœ ì¶œ ë°©ì§€)
Document A: [Para1, Para2, Para3]
Train: [Document B, C, D]  # ë‹¤ë¥¸ ë¬¸ì„œë“¤
Val:   [Document A]        # ì™„ì „íˆ ë¶„ë¦¬ëœ ë¬¸ì„œ
```

### 3. ì•™ìƒë¸” ê°€ì¤‘ì¹˜ ìµœì í™”
```python
# ì´ì „: ê· ë“± ê°€ì¤‘ì¹˜
ensemble = (model1_pred + model2_pred + model3_pred) / 3

# ì´í›„: ìµœì í™”ëœ ê°€ì¤‘ì¹˜
ensemble = w1*model1_pred + w2*model2_pred + w3*model3_pred
# where w1, w2, w3 are optimized using scipy.optimize
```

---

## ğŸ”§ ì‹¤í–‰ ì‹œ ë³€ê²½ì‚¬í•­

### ê¸°ì¡´ ì‹¤í–‰ ë°©ë²•
```bash
python main.py  # ê³ ì •ëœ KLUE/BERT, BCE Loss
```

### ìƒˆë¡œìš´ ì‹¤í–‰ ë°©ë²•
```bash
# ë‹¤ì–‘í•œ ëª¨ë¸ê³¼ ì†ì‹¤ í•¨ìˆ˜ ì¡°í•©
python train_improved.py --model koelectra --loss focal --env gpu
python train_improved.py --model kcbert --loss focal --env gpu
python train_improved.py --model klue-bert --loss bce_weighted --env gpu

# ëª¨ë¸ í…ŒìŠ¤íŠ¸
python test_koelectra.py --compare
```

---

## ğŸ“ˆ ì˜ˆìƒ ì„±ëŠ¥ ê°œì„  ê²½ë¡œ

### Phase 1: ê¸°ë³¸ ê°œì„  (0.5 â†’ 0.65)
- Focal Loss ì ìš©
- ë™ì  ê°€ì¤‘ì¹˜ ê³„ì‚°

### Phase 2: ëª¨ë¸ ìµœì í™” (0.65 â†’ 0.7)
- KoELECTRA ëª¨ë¸ ì‚¬ìš©
- í•œêµ­ì–´ íŠ¹í™” ì„¤ì •

### Phase 3: ë°ì´í„° ê°œì„  (0.7 â†’ 0.75)
- ë¬¸ì„œë³„ êµì°¨ê²€ì¦
- ë°ì´í„° ì¦ê°• ì ìš©

### Phase 4: ì•™ìƒë¸” ìµœì í™” (0.75 â†’ 0.8+)
- ìµœì í™”ëœ ê°€ì¤‘ì¹˜ ì•™ìƒë¸”
- ì˜¨ë„ ìŠ¤ì¼€ì¼ë§ ì ìš©

---

## ğŸ¯ í•µì‹¬ ë³€ê²½ì‚¬í•­ ìš”ì•½

1. **ì†ì‹¤ í•¨ìˆ˜**: BCE â†’ Focal Loss (í´ë˜ìŠ¤ ë¶ˆê· í˜• í•´ê²°)
2. **ëª¨ë¸**: KLUE/BERT â†’ KoELECTRA (í•œêµ­ì–´ ìµœì í™”)
3. **êµì°¨ê²€ì¦**: ë¬¸ë‹¨ë³„ â†’ ë¬¸ì„œë³„ (ë°ì´í„° ìœ ì¶œ ë°©ì§€)
4. **ë°ì´í„° ì¦ê°•**: ì—†ìŒ â†’ í•œêµ­ì–´ íŠ¹í™” ì¦ê°•
5. **ì•™ìƒë¸”**: ê· ë“± ê°€ì¤‘ì¹˜ â†’ ìµœì í™”ëœ ê°€ì¤‘ì¹˜
6. **ì‹¤í–‰**: ê³ ì • ì„¤ì • â†’ ìœ ì—°í•œ ì„¤ì • ì„ íƒ

ì´ëŸ¬í•œ ë³€ê²½ìœ¼ë¡œ **AUC 0.5 â†’ 0.75+** ì„±ëŠ¥ í–¥ìƒì„ ê¸°ëŒ€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

---

*ìƒì„±ì¼: 2025-01-09*  
*ì‘ì„±ì: Claude Code Assistant*